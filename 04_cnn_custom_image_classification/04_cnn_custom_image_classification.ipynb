{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77d3f0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/data_setup.py\n",
    "import os\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def create_dataloaders(train_dir, \n",
    "                       test_dir, \n",
    "                       train_transform,\n",
    "                       test_transform,\n",
    "                       batch_size):\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "    test_dataset = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "    \n",
    "    class_names = train_dataset.classes\n",
    "    \n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_data_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_data_loader, test_data_loader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93beeca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/model_builder.py\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ImageClassificationModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels, hidden_channels, output_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, hidden_channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.layer_3 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_channels*16*16, output_channels)\n",
    "        )\n",
    "     \n",
    "    def forward(self, x):\n",
    "        return self.layer_3(self.layer_2(self.layer_1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ac00167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/engine.py\n",
    "import torch\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc\n",
    "\n",
    "\n",
    "def train_step(\n",
    "    model, \n",
    "    data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device\n",
    "):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    #Run through all the batches\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        y_logits = model(X)\n",
    "\n",
    "        loss = loss_fn(y_logits, y)\n",
    "        train_loss = train_loss + loss\n",
    "\n",
    "        acc = accuracy_fn(y, torch.argmax(y_logits, dim=1))\n",
    "        train_acc = train_acc + acc\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = train_loss / len(data_loader)\n",
    "    train_acc = train_acc / len(data_loader)\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def test_step(\n",
    "    model, \n",
    "    data_loader,\n",
    "    loss_fn,\n",
    "    device\n",
    "):\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        #Run through all the batches\n",
    "        for batch, (X, y) in enumerate(data_loader):\n",
    "\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_logits = model(X)\n",
    "\n",
    "            loss = loss_fn(y_logits, y)\n",
    "            test_loss = test_loss + loss\n",
    "\n",
    "            acc = accuracy_fn(y, torch.argmax(y_logits, dim=1))\n",
    "            test_acc = test_acc + acc\n",
    "\n",
    "        test_loss = test_loss / len(data_loader)\n",
    "        test_acc = test_acc / len(data_loader)\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "\n",
    "def train(\n",
    "    model, \n",
    "    train_data_loader,\n",
    "    test_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs\n",
    "):\n",
    "    \n",
    "    results = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in torch.arange(epochs):\n",
    "    \n",
    "        train_loss, train_acc = train_step(model, \n",
    "                                           train_data_loader, \n",
    "                                           loss_fn, \n",
    "                                           optimizer, \n",
    "                                           device)\n",
    "\n",
    "        test_loss, test_acc = test_step(model, \n",
    "                                       test_data_loader, \n",
    "                                       loss_fn,\n",
    "                                       device)\n",
    "        \n",
    "        print(\n",
    "            f'Epoch: {epoch+1} | '\n",
    "            f'train_loss: {train_loss} | '\n",
    "            f'train_acc: {train_acc} | '\n",
    "            f'test_loss: {test_loss} | '\n",
    "            f'test_acc: {test_acc}'\n",
    "        )\n",
    "        \n",
    "        results['train_loss']. append(train_loss)\n",
    "        results['train_acc']. append(train_acc)\n",
    "        results['test_loss']. append(test_loss)\n",
    "        results['test_acc']. append(test_acc)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "942805cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/utils.py\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def save_model(model,\n",
    "               target_dir,\n",
    "               model_name):\n",
    "\n",
    "\n",
    "    # Create target directory\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True,\n",
    "                        exist_ok=True)\n",
    "\n",
    "    # Create model save path\n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "    model_save_path = target_dir_path / model_name\n",
    "\n",
    "    # Save the model state_dict()\n",
    "    print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "    torch.save(obj=model.state_dict(), \n",
    "               f=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d2085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/train.py\n",
    "import os\n",
    "import torch\n",
    "import data_setup, engine, model_builder, utils\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "# Setup hyperparameters\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_UNITS = 20\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# Setup directories\n",
    "train_dir = \"data/pizza_steak_sushi/train\"\n",
    "test_dir = \"data/pizza_steak_sushi/test\"\n",
    "\n",
    "# Setup target device\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "train_transform_trivial_augment = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.ToTensor() \n",
    "])\n",
    "\n",
    "# Create testing transform (no data augmentation)\n",
    "test_transform_trivial_augment = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    train_transform=train_transform_trivial_augment,\n",
    "    test_transform=test_transform_trivial_augment,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "model = model_builder.ImageClassificationModel(\n",
    "    input_channels=3,\n",
    "    hidden_channels=HIDDEN_UNITS,\n",
    "    output_channels=len(class_names)\n",
    ").to(device)\n",
    "\n",
    "# Set loss and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "\n",
    "# Start training with help from engine.py\n",
    "engine.train(model,\n",
    "             train_dataloader,\n",
    "             test_dataloader,\n",
    "             loss_fn,\n",
    "             optimizer,\n",
    "             device,\n",
    "             NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43f44e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <CDAC6E34-8608-3E70-8B2F-32BCD38E90FB> /opt/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.3551325798034668 | train_acc: 43.359375 | test_loss: 1.6381109952926636 | test_acc: 25.757575757575754\n",
      "Epoch: 2 | train_loss: 1.140576958656311 | train_acc: 30.859375 | test_loss: 1.0977433919906616 | test_acc: 46.21212121212121\n",
      "Epoch: 3 | train_loss: 1.1004348993301392 | train_acc: 29.6875 | test_loss: 1.0996538400650024 | test_acc: 30.018939393939394\n",
      "Epoch: 4 | train_loss: 1.0964906215667725 | train_acc: 42.578125 | test_loss: 1.0941100120544434 | test_acc: 43.93939393939394\n",
      "Epoch: 5 | train_loss: 1.102189302444458 | train_acc: 30.46875 | test_loss: 1.094565510749817 | test_acc: 37.973484848484844\n",
      "Epoch: 6 | train_loss: 1.1003081798553467 | train_acc: 30.46875 | test_loss: 1.0993245840072632 | test_acc: 33.996212121212125\n",
      "Epoch: 7 | train_loss: 1.1028800010681152 | train_acc: 30.46875 | test_loss: 1.1037713289260864 | test_acc: 30.018939393939394\n",
      "Epoch: 8 | train_loss: 1.1017264127731323 | train_acc: 26.953125 | test_loss: 1.0999056100845337 | test_acc: 25.757575757575754\n",
      "Epoch: 9 | train_loss: 1.098838448524475 | train_acc: 29.296875 | test_loss: 1.0987414121627808 | test_acc: 21.78030303030303\n",
      "Epoch: 10 | train_loss: 1.096412181854248 | train_acc: 39.84375 | test_loss: 1.094254970550537 | test_acc: 44.223484848484844\n",
      "Epoch: 11 | train_loss: 1.1030124425888062 | train_acc: 28.125 | test_loss: 1.0913207530975342 | test_acc: 44.223484848484844\n",
      "Epoch: 12 | train_loss: 1.0950701236724854 | train_acc: 40.234375 | test_loss: 1.0923720598220825 | test_acc: 44.223484848484844\n",
      "Epoch: 13 | train_loss: 1.1023457050323486 | train_acc: 28.125 | test_loss: 1.096426010131836 | test_acc: 40.246212121212125\n",
      "Epoch: 14 | train_loss: 1.09979248046875 | train_acc: 28.125 | test_loss: 1.0930737257003784 | test_acc: 44.223484848484844\n",
      "Epoch: 15 | train_loss: 1.1070616245269775 | train_acc: 27.734375 | test_loss: 1.1009851694107056 | test_acc: 25.757575757575754\n",
      "Epoch: 16 | train_loss: 1.0956425666809082 | train_acc: 41.40625 | test_loss: 1.1026519536972046 | test_acc: 23.768939393939394\n",
      "Epoch: 17 | train_loss: 1.0934478044509888 | train_acc: 41.40625 | test_loss: 1.1021496057510376 | test_acc: 29.734848484848484\n",
      "Epoch: 18 | train_loss: 1.0909631252288818 | train_acc: 41.40625 | test_loss: 1.106393814086914 | test_acc: 27.746212121212125\n",
      "Epoch: 19 | train_loss: 1.0890841484069824 | train_acc: 41.40625 | test_loss: 1.113686203956604 | test_acc: 25.757575757575754\n",
      "Epoch: 20 | train_loss: 1.1065969467163086 | train_acc: 29.296875 | test_loss: 1.1151691675186157 | test_acc: 27.746212121212125\n"
     ]
    }
   ],
   "source": [
    "%run -i 'src/train.py'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
